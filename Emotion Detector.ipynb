{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import base64\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import gradio\n",
    "from io import BytesIO\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ALI\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\ALI\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\ALI\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.h5') # found random emotion detector model on github ''(its not very accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(prediction):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        emotion_dict = {0: \"DANGEROUS\", 1: \"DANGEROUS\", 2: \"DANGEROUS\", 3: \"DANGEROUS\", 4: \"DANGEROUS\", 5: \"DANGEROUS\", 6: \"DANGEROUS\"}\n",
    "        return emotion_dict[prediction] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resize_and_crop(img, size, crop_type='top'):\n",
    "    \"\"\"\n",
    "    Resize and crop an image to fit the specified size.\n",
    "    args:\n",
    "        img_path: path for the image to resize.\n",
    "        modified_path: path to store the modified image.\n",
    "        size: `(width, height)` tuple.\n",
    "        crop_type: can be 'top', 'middle' or 'bottom', depending on this\n",
    "            value, the image will cropped getting the 'top/left', 'midle' or\n",
    "            'bottom/rigth' of the image to fit the size.\n",
    "    raises:\n",
    "        Exception: if can not open the file in img_path of there is problems\n",
    "            to save the image.\n",
    "        ValueError: if an invalid `crop_type` is provided.\n",
    "    \"\"\"\n",
    "    # Get current and desired ratio for the images\n",
    "    img_ratio = img.size[0] / float(img.size[1])\n",
    "    ratio = size[0] / float(size[1])\n",
    "    # The image is scaled/cropped vertically or horizontally depending on the ratio\n",
    "    if ratio > img_ratio:\n",
    "        img = img.resize((size[0], size[0] * img.size[1] / img.size[0]),\n",
    "                         Image.ANTIALIAS)\n",
    "        # Crop in the top, middle or bottom\n",
    "        if crop_type == 'top':\n",
    "            box = (0, 0, img.size[0], size[1])\n",
    "        elif crop_type == 'middle':\n",
    "            box = (0, (img.size[1] - size[1]) / 2, img.size[0], (img.size[1] + size[1]) / 2)\n",
    "        elif crop_type == 'bottom':\n",
    "            box = (0, img.size[1] - size[1], img.size[0], img.size[1])\n",
    "        else:\n",
    "            raise ValueError('ERROR: invalid value for crop_type')\n",
    "        img = img.crop(box)\n",
    "    elif ratio < img_ratio:\n",
    "        img = img.resize((size[1] * img.size[0] / img.size[1], size[1]),\n",
    "                         Image.ANTIALIAS)\n",
    "        # Crop in the top, middle or bottom\n",
    "        if crop_type == 'top':\n",
    "            box = (0, 0, size[0], img.size[1])\n",
    "        elif crop_type == 'middle':\n",
    "            box = ((img.size[0] - size[0]) / 2, 0, (img.size[0] + size[0]) / 2, img.size[1])\n",
    "        elif crop_type == 'bottom':\n",
    "            box = (img.size[0] - size[0], 0, img.size[0], img.size[1])\n",
    "        else:\n",
    "            raise ValueError('ERROR: invalid value for crop_type')\n",
    "        img = img.crop(box)\n",
    "    else:\n",
    "        img = img.resize((size[0], size[1]),\n",
    "                         Image.ANTIALIAS)\n",
    "        # If the scale is the same, we do not need to crop\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_p(imgstring):      \n",
    "        content = imgstring.split(';')[1]\n",
    "        image_encoded = content.split(',')[1]\n",
    "        body = base64.decodebytes(image_encoded.encode('utf-8'))\n",
    "        im = Image.open(BytesIO(base64.b64decode(image_encoded))).convert('L')\n",
    "        im = resize_and_crop(im, (28, 28))\n",
    "        array = np.array(im).flatten().reshape(1, -1)\n",
    "        return array \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALI\\Desktop\\gradiome\\gradio.py:191: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 191 of the file C:\\Users\\ALI\\Desktop\\gradiome\\gradio.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  input_soup = BeautifulSoup(input_page.read())\n",
      "C:\\Users\\ALI\\Desktop\\gradiome\\gradio.py:192: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 192 of the file C:\\Users\\ALI\\Desktop\\gradiome\\gradio.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  output_soup = BeautifulSoup(output_page.read())\n",
      "C:\\Users\\ALI\\Desktop\\gradiome\\gradio.py:196: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 196 of the file C:\\Users\\ALI\\Desktop\\gradiome\\gradio.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  all_io_soup = BeautifulSoup(all_io_page.read())\n",
      "Error in connection handler\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ALI\\Anaconda3\\lib\\site-packages\\websockets\\server.py\", line 169, in handler\n",
      "    yield from self.ws_handler(self, path)\n",
      "  File \"C:\\Users\\ALI\\Desktop\\gradiome\\gradio.py\", line 224, in communicate\n",
      "    processed_input = self.input_interface._pre_process(await websocket.recv())\n",
      "  File \"C:\\Users\\ALI\\Anaconda3\\lib\\site-packages\\websockets\\protocol.py\", line 434, in recv\n",
      "    yield from self.ensure_open()\n",
      "  File \"C:\\Users\\ALI\\Anaconda3\\lib\\site-packages\\websockets\\protocol.py\", line 646, in ensure_open\n",
      "    ) from self.transfer_data_exc\n",
      "websockets.exceptions.ConnectionClosed: WebSocket connection is closed: code = 1001 (going away), no reason\n",
      "Error in connection handler\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ALI\\Anaconda3\\lib\\site-packages\\websockets\\server.py\", line 169, in handler\n",
      "    yield from self.ws_handler(self, path)\n",
      "  File \"C:\\Users\\ALI\\Desktop\\gradiome\\gradio.py\", line 224, in communicate\n",
      "    processed_input = self.input_interface._pre_process(await websocket.recv())\n",
      "  File \"C:\\Users\\ALI\\Anaconda3\\lib\\site-packages\\websockets\\protocol.py\", line 434, in recv\n",
      "    yield from self.ensure_open()\n",
      "  File \"C:\\Users\\ALI\\Anaconda3\\lib\\site-packages\\websockets\\protocol.py\", line 646, in ensure_open\n",
      "    ) from self.transfer_data_exc\n",
      "websockets.exceptions.ConnectionClosed: WebSocket connection is closed: code = 1001 (going away), no reason\n"
     ]
    }
   ],
   "source": [
    "iface = gradio.Interface(input='webcam',output='class',model_obj=model, model_type='keras',postprocessing_fn=postprocessing)\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
