{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import gradio\n",
    "from keras.models import load_model\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load an Facial Emotion Detector Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../.models/emotion.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_p(prediction): \n",
    "    emotional_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}\n",
    "    return emotional_dict[prediction.squeeze().argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Gradio is in beta stage, please report all bugs to: a12d@stanford.edu\n",
      "Model is running locally at: http://localhost:7860/interface.html\n",
      "To create a public link, set `share=True` in the argument to `launch()`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"http://localhost:7860/interface.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2725311ca20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('http://localhost:7860/interface.html', None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [06/Mar/2019 12:13:52] \"GET /interface.html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Mar/2019 12:13:52] \"GET /static/css/gradio.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Mar/2019 12:13:52] \"GET /static/js/all-io.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Mar/2019 12:13:52] \"GET /static/js/image-upload-input.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Mar/2019 12:13:52] \"GET /static/js/class-output.js HTTP/1.1\" 200 -\n",
      "Error in connection handler\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\islam\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\websockets\\server.py\", line 169, in handler\n",
      "    yield from self.ws_handler(self, path)\n",
      "  File \"C:\\Users\\islam\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\gradio\\interface.py\", line 106, in communicate\n",
      "    prediction = self.predict(processed_input)\n",
      "  File \"C:\\Users\\islam\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\gradio\\interface.py\", line 122, in predict\n",
      "    return self.model_obj.predict(preprocessed_input)\n",
      "  File \"C:\\Users\\islam\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1149, in predict\n",
      "    x, _, _ = self._standardize_user_data(x)\n",
      "  File \"C:\\Users\\islam\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 751, in _standardize_user_data\n",
      "    exception_prefix='input')\n",
      "  File \"C:\\Users\\islam\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 138, in standardize_input_data\n",
      "    str(data_shape))\n",
      "ValueError: Error when checking input: expected conv2d_1_input to have shape (48, 48, 1) but got array with shape (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "iface = gradio.Interface(inputs='imageupload', outputs='label', model=model, model_type='keras')\n",
    "iface.launch(share=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
